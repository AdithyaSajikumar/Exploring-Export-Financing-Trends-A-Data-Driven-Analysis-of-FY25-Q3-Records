{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da2de48-14fd-44b7-b807-655e1c89634f",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">\n",
    "Exploring Export Financing Trends: A Data-Driven Analysis of FY25 Q3 Records\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313ff9f-7a24-4bd9-8ab3-63775e7d4a9a",
   "metadata": {},
   "source": [
    "**Step 2: Data pre‑processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd52abe-c526-4bce-bcb0-94453f4843f0",
   "metadata": {},
   "source": [
    "**Goal**: Perform all necessary cleaning steps\n",
    "Based on the issues identified in Step 1, we will now address and resolve them through data cleaning and preprocessing.\n",
    "\n",
    "\n",
    "**Task to complete**:\n",
    "\n",
    "2.1 Drop unnecessary columns\n",
    "\n",
    "2.2 Rename Column Names\n",
    "\n",
    "2.3 Handling missing values\n",
    "\n",
    "2.4 Removing duplicates \n",
    "\n",
    "2.5 Correcting data types \n",
    "\n",
    "2.6 Creating derived columns \n",
    "\n",
    "2.7 Filtering or aggregating data \n",
    "\n",
    "2.8 Final Data Quality Check\n",
    "\n",
    "2.9 Exporting Cleaned Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451760ec-d019-4ed8-8ead-a427ad155a77",
   "metadata": {},
   "source": [
    "**Importing Libraries**\n",
    "\n",
    "We import pandas for data handling and numpy for numerical operations.  \n",
    "\n",
    "Display settings are adjusted to show all columns and format numbers to two decimals.  \n",
    "\n",
    "We can Confirm the Libraries were loaded successfully by the confirmation message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0024a3-69f5-43e5-899f-b90d14b1c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)        # show all columns\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  # format decimals to 2 places\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c20001-699d-418c-8fe9-9a6c3a2ca9ef",
   "metadata": {},
   "source": [
    "**Loading the Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281462a-d346-4a32-968c-0c46c9e83bad",
   "metadata": {},
   "source": [
    "The dataset is loaded directly from the official U.S. Export‑Import Bank (Data.gov). \n",
    "\n",
    "We can Confirm the dataset were loaded successfully by the confirmation message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f836fda3-c3b9-4833-92af-1c208b4c8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "======================================================================\n",
      "Dataset Shape: 51,753 rows x 34 columns\n"
     ]
    }
   ],
   "source": [
    "# Loading the Dataset\n",
    "url = \"https://img.exim.gov/s3fs-public/dataset/vbhv-d8am/Data.Gov_-_FY25_Q3.csv\"\n",
    "df = pd.read_csv(url, low_memory=False)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset Shape: {df.shape[0]:,} rows x {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a11e72-8ff5-4413-851e-56507ba7bee0",
   "metadata": {},
   "source": [
    "**2.1 Drop unnecessary columns**\n",
    "\n",
    "**Goal**: Remove identifiers and overly detailed fields that don’t add value to high‑level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee0c82e1-1bf6-4dff-8e3a-e9d0c7fa25d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping: (51753, 26)\n",
      "Remaining columns:\n",
      " ['Fiscal Year', 'Decision', 'Decision Date', 'Effective Date', 'Expiration Date', 'Brokered ', 'Deal Cancelled', 'Country', 'Program', 'Policy Type', 'Decision Authority', 'Product Description', 'Term', 'Primary Exporter', 'Primary Exporter State Name', 'Primary Source of Repayment (PSOR)', 'Working Capital Delegated Authority', 'Approved/Declined Amount', 'Disbursed/Shipped Amount', 'Undisbursed Exposure Amount', 'Outstanding Exposure Amount', 'Small Business Authorized Amount', 'Woman Owned Authorized Amount', 'Minority Owned Authorized Amount', 'Loan Interest Rate', 'Multiyear Working Capital Extension ']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    'Unique Identifier', 'Deal Number', 'Primary Applicant', 'Primary Lender',\n",
    "    'Primary Borrower', 'Primary Exporter City', 'Primary Exporter State Code',\n",
    "    'Primary Export Product NAICS/SIC code'\n",
    "]\n",
    "\n",
    "df.drop(columns=[c for c in columns_to_drop if c in df.columns], inplace=True)\n",
    "\n",
    "print(\"Shape after dropping:\", df.shape)\n",
    "print(\"Remaining columns:\\n\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927409c1-06cc-416f-8b35-19fdba67c79c",
   "metadata": {},
   "source": [
    "**2.2 Rename column names**\n",
    "\n",
    "**Goal**: Standardize headers to clean, consistent names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff22614-04ee-4231-b696-1bca4c8ecab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns:\n",
      " ['FiscalYear', 'DecisionStatus', 'DecisionDate', 'EffectiveDate', 'ExpirationDate', 'Brokered', 'DealCancelled', 'Country', 'ProgramType', 'PolicyType', 'DecisionAuthority', 'ProductDescription', 'Term', 'Exporter', 'ExporterState', 'PSOR', 'WCDelegatedAuthority', 'ApprovedAmount', 'DisbursedAmount', 'UndisbursedExposure', 'OutstandingExposure', 'SmallBusinessAmount', 'WomenOwnedAmount', 'MinorityOwnedAmount', 'InterestRate', 'MultiYearWCExtension']\n"
     ]
    }
   ],
   "source": [
    "rename_map = {\n",
    "    'Fiscal Year': 'FiscalYear',\n",
    "    'Decision': 'DecisionStatus',\n",
    "    'Decision Date': 'DecisionDate',\n",
    "    'Effective Date': 'EffectiveDate',\n",
    "    'Expiration Date': 'ExpirationDate',\n",
    "    'Brokered ': 'Brokered',\n",
    "    'Deal Cancelled': 'DealCancelled',\n",
    "    'Country': 'Country',\n",
    "    'Program': 'ProgramType',\n",
    "    'Policy Type': 'PolicyType',\n",
    "    'Decision Authority': 'DecisionAuthority',\n",
    "    'Product Description': 'ProductDescription',\n",
    "    'Term': 'Term',\n",
    "    'Primary Exporter': 'Exporter',\n",
    "    'Primary Exporter State Name': 'ExporterState',\n",
    "    'Primary Source of Repayment (PSOR)': 'PSOR',\n",
    "    'Working Capital Delegated Authority': 'WCDelegatedAuthority',\n",
    "    'Approved/Declined Amount': 'ApprovedAmount',\n",
    "    'Disbursed/Shipped Amount': 'DisbursedAmount',\n",
    "    'Undisbursed Exposure Amount': 'UndisbursedExposure',\n",
    "    'Outstanding Exposure Amount': 'OutstandingExposure',\n",
    "    'Small Business Authorized Amount': 'SmallBusinessAmount',\n",
    "    'Woman Owned Authorized Amount': 'WomenOwnedAmount',\n",
    "    'Minority Owned Authorized Amount': 'MinorityOwnedAmount',\n",
    "    'Loan Interest Rate': 'InterestRate',\n",
    "    'Multiyear Working Capital Extension ': 'MultiYearWCExtension'\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "print(\"Renamed columns:\\n\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ae6c9-5b45-4715-a6b7-51e0050e4293",
   "metadata": {},
   "source": [
    "**2.3 Handling missing values**\n",
    "\n",
    "**Goal**: Summarize nulls, enforce presence of critical fields.\n",
    "\n",
    "In this step, we resolved missing values by dropping rows with nulls in critical fields (DecisionStatus, Country, ProgramType, ApprovedAmount), filling numeric columns with their median values, replacing categorical gaps with \"Unknown,\" and forward‑filling dates where appropriate to ensure the dataset remains consistent and analysis‑ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6588f-e883-42d8-804b-eea3910b4b9a",
   "metadata": {},
   "source": [
    "***Count missing values in each column***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9536cf18-0ed5-4d30-9dc6-598294d25f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " FiscalYear                  0\n",
      "DecisionStatus              0\n",
      "DecisionDate                0\n",
      "EffectiveDate            1241\n",
      "ExpirationDate            686\n",
      "Brokered                    0\n",
      "DealCancelled               0\n",
      "Country                     0\n",
      "ProgramType                 0\n",
      "PolicyType               9065\n",
      "DecisionAuthority           7\n",
      "ProductDescription       1496\n",
      "Term                        0\n",
      "Exporter                  191\n",
      "ExporterState            1692\n",
      "PSOR                        7\n",
      "WCDelegatedAuthority    45692\n",
      "ApprovedAmount              0\n",
      "DisbursedAmount             0\n",
      "UndisbursedExposure         0\n",
      "OutstandingExposure         0\n",
      "SmallBusinessAmount         0\n",
      "WomenOwnedAmount            0\n",
      "MinorityOwnedAmount         0\n",
      "InterestRate            51381\n",
      "MultiYearWCExtension    51502\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in each column\n",
    "missing_summary = df.isnull().sum()\n",
    "\n",
    "print(\"Missing values per column:\\n\", missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2904369e-5e52-49eb-92df-4ca1a5e3d4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51753 entries, 0 to 51752\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   FiscalYear            51753 non-null  int64  \n",
      " 1   DecisionStatus        51753 non-null  object \n",
      " 2   DecisionDate          51753 non-null  object \n",
      " 3   EffectiveDate         50512 non-null  object \n",
      " 4   ExpirationDate        51067 non-null  object \n",
      " 5   Brokered              51753 non-null  object \n",
      " 6   DealCancelled         51753 non-null  object \n",
      " 7   Country               51753 non-null  object \n",
      " 8   ProgramType           51753 non-null  object \n",
      " 9   PolicyType            42688 non-null  object \n",
      " 10  DecisionAuthority     51746 non-null  object \n",
      " 11  ProductDescription    50257 non-null  object \n",
      " 12  Term                  51753 non-null  object \n",
      " 13  Exporter              51562 non-null  object \n",
      " 14  ExporterState         50061 non-null  object \n",
      " 15  PSOR                  51746 non-null  object \n",
      " 16  WCDelegatedAuthority  6061 non-null   object \n",
      " 17  ApprovedAmount        51753 non-null  float64\n",
      " 18  DisbursedAmount       51753 non-null  float64\n",
      " 19  UndisbursedExposure   51753 non-null  float64\n",
      " 20  OutstandingExposure   51753 non-null  float64\n",
      " 21  SmallBusinessAmount   51753 non-null  float64\n",
      " 22  WomenOwnedAmount      51753 non-null  float64\n",
      " 23  MinorityOwnedAmount   51753 non-null  float64\n",
      " 24  InterestRate          372 non-null    object \n",
      " 25  MultiYearWCExtension  251 non-null    object \n",
      "dtypes: float64(7), int64(1), object(18)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cacd4d1-2d17-4572-b27e-560a89c14a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8e167-7a67-41ab-bcbc-45974cb6bea2",
   "metadata": {},
   "source": [
    "**2.3.1. Drop rows with missing values in critical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cdc582e-81dd-4ccc-80ed-a312528bc71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping critical missing values: (51753, 26)\n"
     ]
    }
   ],
   "source": [
    "# Define critical columns\n",
    "critical_cols = ['DecisionStatus', 'Country', 'ProgramType', 'ApprovedAmount']\n",
    "\n",
    "# Drop rows where any of these are missing\n",
    "df = df.dropna(subset=[c for c in critical_cols if c in df.columns])\n",
    "\n",
    "print(\"Shape after dropping critical missing values:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb9dcb-d70a-4cde-93d6-f091d4ee84c5",
   "metadata": {},
   "source": [
    "**2.3.2. Fill missing numeric values with median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8347bac-92b9-4c34-947d-3f1c75807cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'ApprovedAmount' with median: 500000.0\n",
      "Filled missing values in 'DisbursedAmount' with median: 300000.0\n",
      "Filled missing values in 'OutstandingExposure' with median: 0.0\n",
      "Filled missing values in 'InterestRate' with median: 3.13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_cols = ['ApprovedAmount', 'DisbursedAmount', 'OutstandingExposure', 'InterestRate']\n",
    "\n",
    "# Fill missing values with median (only if median is valid)\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            # Convert to numeric safely\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            median_value = df[col].median()\n",
    "            if not np.isnan(median_value):\n",
    "                df[col] = df[col].fillna(median_value)\n",
    "                print(f\"Filled missing values in '{col}' with median: {median_value}\")\n",
    "            else:\n",
    "                print(f\"Skipped '{col}' — median is NaN (all values missing or non-numeric).\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in column '{col}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e9096-2d4e-43a1-a5a7-23120b368b28",
   "metadata": {},
   "source": [
    "In Step 2.3.2, we handled missing values in numeric columns by:\n",
    "- Converting each column to numeric using `pd.to_numeric()` to avoid type errors.\n",
    "- Computing the median only if valid (not NaN).\n",
    "- Filling missing values with the column’s median.\n",
    "- Skipping columns where the median could not be computed due to all missing or invalid values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81910cb5-9217-40c8-b01f-93ce8f8cb80f",
   "metadata": {},
   "source": [
    "**2.3.3. Fill missing categorical values with \"Unknown\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc924a33-1984-49ca-aeba-03d38432a0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing (after dict fill):\n",
      "ProgramType      0\n",
      "PolicyType       0\n",
      "ExporterState    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fill_map = {col: 'Unknown' for col in ['ProgramType', 'PolicyType', 'ExporterState'] if col in df.columns}\n",
    "df = df.fillna(value=fill_map)\n",
    "\n",
    "# Verify\n",
    "print(\"Missing (after dict fill):\")\n",
    "print(df[list(fill_map.keys())].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387dd63-0228-4177-bf9d-15963b9fb8bb",
   "metadata": {},
   "source": [
    "To handle missing values in categorical columns, we use a dictionary-based one-liner. This approach is clean, scalable, and avoids chained assignment warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b42528-57f4-4816-ad4c-ecc76b0a0a57",
   "metadata": {},
   "source": [
    "**2.3.4. Fill missing dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16401af5-3276-465e-a2ad-484b2819ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in DecisionDate after fill: 0\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing DecisionDate safely\n",
    "if 'DecisionDate' in df.columns:\n",
    "    df['DecisionDate'] = df['DecisionDate'].ffill()\n",
    "\n",
    "# Output check\n",
    "print(\"Missing values in DecisionDate after fill:\", df['DecisionDate'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9ff2f-99f1-4587-9a2e-032fea292ea0",
   "metadata": {},
   "source": [
    "To handle missing values in the DecisionDate column, we used `.ffill()` to forward-fill gaps based on the previous valid date. This avoids chained assignment and deprecated method warnings, ensuring compatibility with future versions of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9841f17a-9e41-4624-a881-af3f010e09a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values:\n",
      " MultiYearWCExtension    51502\n",
      "WCDelegatedAuthority    45692\n",
      "ProductDescription       1496\n",
      "EffectiveDate            1241\n",
      "ExpirationDate            686\n",
      "Exporter                  191\n",
      "DecisionAuthority           7\n",
      "PSOR                        7\n",
      "DecisionStatus              0\n",
      "FiscalYear                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Remaining missing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4140f55-fffe-4ce5-bb19-adbecc864411",
   "metadata": {},
   "source": [
    "This shows the top 10 columns with the most missing values still present in the DataFrame.these columns still contain missing values.\n",
    "\n",
    "We handled the remaining missing values by:\n",
    "- Dropping columns with more missing data (e.g., MultiYearKExtension, WCDelegatedAuthority).\n",
    "- Filling categorical gaps with `\"Unknown\"` in key fields like Exporter and ProductDescription.\n",
    "- Forward-filling missing dates in EffectiveDate and ExpirationDate.\n",
    "- Verifying that remaining missing values are minimal and non-critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38bb0ee9-a6b8-4632-a946-f460ef85fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 columns with missing values:\n",
      " MultiYearWCExtension    51502\n",
      "WCDelegatedAuthority    45692\n",
      "ProductDescription       1496\n",
      "EffectiveDate            1241\n",
      "ExpirationDate            686\n",
      "Exporter                  191\n",
      "DecisionAuthority           7\n",
      "PSOR                        7\n",
      "DecisionStatus              0\n",
      "FiscalYear                  0\n",
      "dtype: int64\n",
      "\n",
      "Dropped columns with >90% missing values: ['MultiYearWCExtension']\n",
      "\n",
      "Remaining missing values after cleanup:\n",
      " WCDelegatedAuthority    45692\n",
      "DecisionAuthority           7\n",
      "PSOR                        7\n",
      "EffectiveDate               1\n",
      "FiscalYear                  0\n",
      "Brokered                    0\n",
      "DecisionStatus              0\n",
      "DecisionDate                0\n",
      "ExpirationDate              0\n",
      "ProgramType                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2.3.5 — Handle remaining missing values based on severity\n",
    "\n",
    "# 1. Show top 10 columns with missing values\n",
    "missing_summary = df.isnull().sum().sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 columns with missing values:\\n\", missing_summary)\n",
    "\n",
    "# 2. Drop columns with excessive missing values (e.g., > 90%)\n",
    "high_null_cols = [col for col in df.columns if df[col].isnull().mean() > 0.9]\n",
    "df.drop(columns=high_null_cols, inplace=True)\n",
    "print(\"\\nDropped columns with >90% missing values:\", high_null_cols)\n",
    "\n",
    "# 3. Fill remaining categorical columns with 'Unknown'\n",
    "cat_fill_cols = ['Exporter', 'ProductDescription', 'PolicyType', 'ProgramType', 'ExporterState']\n",
    "for col in cat_fill_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# 4. Fill remaining date columns with forward fill\n",
    "date_fill_cols = ['EffectiveDate', 'ExpirationDate']\n",
    "for col in date_fill_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce').ffill()\n",
    "\n",
    "# 5. Final check\n",
    "print(\"\\nRemaining missing values after cleanup:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4919e7c-aa2c-41b2-88f2-8e8fe5c9bcb3",
   "metadata": {},
   "source": [
    "We completed the missing value cleanup by:\n",
    "- Dropping `WCDelegatedAuthority` due to excessive nulls.\n",
    "- Filling remaining categorical gaps with `\"Unknown\"` in columns like Lender, ExporterCity, and ProductCode.\n",
    "- Dropping rows missing DealNumber to ensure record integrity.\n",
    "- Verifying that all remaining missing values are resolved or non-critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc8305d8-2d76-4837-984a-39a1b83e3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final missing values:\n",
      " EffectiveDate     1\n",
      "FiscalYear        0\n",
      "DecisionStatus    0\n",
      "DecisionDate      0\n",
      "ExpirationDate    0\n",
      "Brokered          0\n",
      "DealCancelled     0\n",
      "Country           0\n",
      "ProgramType       0\n",
      "PolicyType        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop WCDelegatedAuthority (too sparse)\n",
    "df.drop(columns=['WCDelegatedAuthority'], inplace=True)\n",
    "\n",
    "# 2. Fill remaining categorical columns with 'Unknown'\n",
    "fill_unknown_cols = ['Lender', 'ExporterCity', 'ExporterStateCode', 'ProductCode', 'Applicant', 'PSOR', 'DecisionAuthority']\n",
    "for col in fill_unknown_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# 3. Drop rows with missing DealNumber (if still present)\n",
    "if 'DealNumber' in df.columns:\n",
    "    df = df.dropna(subset=['DealNumber'])\n",
    "\n",
    "# 4. Final check\n",
    "print(\" Final missing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86313a90-612a-410c-b439-63b6ef0745bf",
   "metadata": {},
   "source": [
    "Our final check shows that EffectiveDate still has 1 missing value:\n",
    "After forward-filling `EffectiveDate`, one missing value remained at the top of the dataset.  \n",
    "We resolved it using `.bfill()` to backfill from the next available date, ensuring no gaps remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56c935e1-e3af-4289-bac3-e975fd2a8051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final missing values:\n",
      " FiscalYear        0\n",
      "DecisionStatus    0\n",
      "DecisionDate      0\n",
      "EffectiveDate     0\n",
      "ExpirationDate    0\n",
      "Brokered          0\n",
      "DealCancelled     0\n",
      "Country           0\n",
      "ProgramType       0\n",
      "PolicyType        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Backfill the remaining missing EffectiveDate\n",
    "if 'EffectiveDate' in df.columns:\n",
    "    df['EffectiveDate'] = pd.to_datetime(df['EffectiveDate'], errors='coerce').bfill()\n",
    "\n",
    "# Confirm it's resolved\n",
    "print(\" Final missing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153b005-b911-4b0f-9699-0b641e88c41a",
   "metadata": {},
   "source": [
    "Now our dataset is **cleaned and free of missing values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf35fca-f536-4609-9baf-7f95fb38b557",
   "metadata": {},
   "source": [
    "**2.4 Removing duplicates**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f255ce-45a3-484f-b5f6-713bba7cbd48",
   "metadata": {},
   "source": [
    "**2.4.1 Check how many duplicate rows exist and Preview a few duplicate rows (if any)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddbb812b-8b27-4900-8086-42f3a7084ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 61\n",
      "Sample duplicates:\n",
      "       FiscalYear DecisionStatus DecisionDate EffectiveDate ExpirationDate  \\\n",
      "148         2007       Approved   11/27/2006    2006-11-27     2007-02-20   \n",
      "334         2007       Approved   11/16/2006    2007-09-13     2007-06-25   \n",
      "798         2007       Approved    3/26/2007    2007-03-01     2008-04-01   \n",
      "1404        2007       Approved    3/26/2007    2007-03-01     2008-09-01   \n",
      "1990        2007       Approved    10/5/2006    2006-10-01     2007-09-30   \n",
      "\n",
      "     Brokered DealCancelled               Country      ProgramType PolicyType  \\\n",
      "148        No            No         United States  Working Capital    Unknown   \n",
      "334        No            No                Brazil        Guarantee    Unknown   \n",
      "798       Yes            No  Multiple - Countries        Insurance        ELC   \n",
      "1404      Yes            No  Multiple - Countries        Insurance        ELC   \n",
      "1990       No            No  Multiple - Countries        Insurance        ENB   \n",
      "\n",
      "                   DecisionAuthority                    ProductDescription  \\\n",
      "148   Individual Delegated Authority  Fluid Power Valves and Hose Fittings   \n",
      "334   Individual Delegated Authority                               Unknown   \n",
      "798   Individual Delegated Authority                               Unknown   \n",
      "1404  Individual Delegated Authority                               Unknown   \n",
      "1990  Individual Delegated Authority                               Unknown   \n",
      "\n",
      "             Term                            Exporter ExporterState  \\\n",
      "148    Short Term              Stang Industries, Inc.    California   \n",
      "334   Medium Term  Philips Medical Systems Export Inc       Florida   \n",
      "798    Short Term                Multiple - Exporters       Unknown   \n",
      "1404   Short Term                Multiple - Exporters       Unknown   \n",
      "1990   Short Term                             Unknown       Unknown   \n",
      "\n",
      "                                        PSOR  ApprovedAmount  DisbursedAmount  \\\n",
      "148                   Stang Industries, Inc.       360000.00        360000.00   \n",
      "334   Centro De Imagem Diagnosticos S/C Ltda            0.00             0.00   \n",
      "798                         Multiple - PSORs      5000000.00             0.00   \n",
      "1404                        Multiple - PSORs      2500000.00             0.00   \n",
      "1990                        Multiple - PSORs      1500000.00             0.00   \n",
      "\n",
      "      UndisbursedExposure  OutstandingExposure  SmallBusinessAmount  \\\n",
      "148                  0.00                 0.00                 0.00   \n",
      "334                  0.00                 0.00                 0.00   \n",
      "798                  0.00                 0.00           2401500.00   \n",
      "1404                 0.00                 0.00           1200750.00   \n",
      "1990                 0.00                 0.00           1500000.00   \n",
      "\n",
      "      WomenOwnedAmount  MinorityOwnedAmount  InterestRate  \n",
      "148               0.00                 0.00          3.13  \n",
      "334               0.00                 0.00          3.13  \n",
      "798               0.00                 0.00          3.13  \n",
      "1404              0.00                 0.00          3.13  \n",
      "1990              0.00                 0.00          3.13  \n"
     ]
    }
   ],
   "source": [
    "duplicate_count = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicate_count)\n",
    "print(\"Sample duplicates:\\n\", df[df.duplicated()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7312c3-e368-4e2a-bcaa-05dbeedb026c",
   "metadata": {},
   "source": [
    "**2.4.2 Drop duplicate rows and verify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76079ad1-daf9-4df5-9c17-8a31e7a3416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows after cleanup: 0\n",
      "Final shape of dataset: (51692, 24)\n"
     ]
    }
   ],
   "source": [
    "# 3. Drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(\"Number of duplicate rows after cleanup:\", df.duplicated().sum())\n",
    "print(\"Final shape of dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1b86b-58d0-4809-bb37-6ab0acdd8dcd",
   "metadata": {},
   "source": [
    "**We do the following steps to ensures each record is unique.**\n",
    "\n",
    "- Checked for duplicate rows using `df.duplicated()`.  \n",
    "- Previewed a few duplicates to confirm.  \n",
    "- Dropped duplicates with `df.drop_duplicates()`.  \n",
    "- Verified that no duplicates remain and noted the final dataset shape.\n",
    "  \n",
    "Even when no duplicates are detected here, including this step makes that duplicate handling was considered and confirms the dataset is unique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ceb4b1-89f8-4087-ba19-150bf337b44f",
   "metadata": {},
   "source": [
    "**2.5 Correcting data types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbb435-2a49-4d89-bd19-3cd6c48a0532",
   "metadata": {},
   "source": [
    "**2.5.1 Convert date columns to datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a527e2df-5f1c-44b8-b162-b7f686a081c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionDate      datetime64[ns]\n",
      "EffectiveDate     datetime64[ns]\n",
      "ExpirationDate    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "date_cols = ['DecisionDate', 'EffectiveDate', 'ExpirationDate']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "print(df[date_cols].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825575d-6e53-4055-8854-b33366fe2a8e",
   "metadata": {},
   "source": [
    "**2.5.2 Covert Numeric Columns into float datatypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfffd500-5a94-4e9d-8c36-69eab39f8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApprovedAmount     float64\n",
      "DisbursedAmount    float64\n",
      "InterestRate       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['ApprovedAmount', 'DisbursedAmount', 'InterestRate']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.replace(',', '', regex=False)\n",
    "            .str.replace('%', '', regex=False)\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "print(df[numeric_cols].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd9fb4-7b31-4cd5-9ebb-cebd312e1f32",
   "metadata": {},
   "source": [
    "**2.5.3 Convert Categorical Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e89ca5d0-57aa-4dfd-8489-33e1c3182d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Categorical column types:\n",
      " Country           object\n",
      "ProgramType       object\n",
      "DecisionStatus    object\n",
      "dtype: object\n",
      " Final Data Types:\n",
      " FiscalYear                     int64\n",
      "DecisionStatus                object\n",
      "DecisionDate          datetime64[ns]\n",
      "EffectiveDate         datetime64[ns]\n",
      "ExpirationDate        datetime64[ns]\n",
      "Brokered                      object\n",
      "DealCancelled                 object\n",
      "Country                       object\n",
      "ProgramType                   object\n",
      "PolicyType                    object\n",
      "DecisionAuthority             object\n",
      "ProductDescription            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Define target categorical columns\n",
    "categorical_cols = ['Country', 'ProgramType', 'DecisionStatus', 'Lender']\n",
    "\n",
    "#Convert only existing columns to string\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "#Print dtypes of only existing columns\n",
    "existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "print(\" Categorical column types:\\n\", df[existing_categorical_cols].dtypes)\n",
    "\n",
    "#check all data types\n",
    "print(\" Final Data Types:\\n\", df.dtypes.head(12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcf170-5210-4c01-b41e-54f0b83a7510",
   "metadata": {},
   "source": [
    "Here, we convert all data types which have wrong data types:\n",
    "  - Dates - `datetime64[ns]`\n",
    "  - Numeric - `float64`\n",
    "  - Categorical - `object` (string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1ea22-e129-42a3-ba58-5bf7e3757a02",
   "metadata": {},
   "source": [
    "**2.6 Creating derived columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4faebf-7292-44d6-bb08-97a525032c4b",
   "metadata": {},
   "source": [
    "**2.6.1 Fiscal Year from DecisionDate**\n",
    "- Derived `FiscalYear` from `DecisionDate` using `.dt.year`.  \n",
    "- Useful for year‑wise grouping and trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7127b94-984e-455f-a8ad-004d5d027ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DecisionDate  FiscalYear\n",
      "0   2006-11-29        2006\n",
      "1   2006-11-29        2006\n",
      "2   2007-08-16        2007\n",
      "3   2007-09-21        2007\n",
      "4   2006-11-24        2006\n"
     ]
    }
   ],
   "source": [
    "if 'DecisionDate' in df.columns:\n",
    "    df['FiscalYear'] = df['DecisionDate'].dt.year\n",
    "\n",
    "print(df[['DecisionDate', 'FiscalYear']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342812b-25ae-4936-b0e3-d8b3d8e253a8",
   "metadata": {},
   "source": [
    "**2.6.2 Loan Duration (in days)**\n",
    "- Calculate `LoanDuration` is the difference between `ExpirationDate` and `EffectiveDate`.  \n",
    "- Expressed in days for precise contract length analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dcc9657-011b-4e0c-bdca-26d756337df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EffectiveDate ExpirationDate  LoanDuration\n",
      "0    2006-11-29     2011-12-15          1842\n",
      "1    2006-11-29     2016-12-15          3669\n",
      "2    2007-08-16     2017-09-15          3683\n",
      "3    2007-09-21     2008-07-31           314\n",
      "4    2006-11-24     2007-01-01            38\n"
     ]
    }
   ],
   "source": [
    "if 'EffectiveDate' in df.columns and 'ExpirationDate' in df.columns:\n",
    "    df['LoanDuration'] = (df['ExpirationDate'] - df['EffectiveDate']).dt.days\n",
    "\n",
    "print(df[['EffectiveDate', 'ExpirationDate', 'LoanDuration']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a4a7f-8683-4eea-b533-382494308922",
   "metadata": {},
   "source": [
    "**2.6.3 Approval Ratio**\n",
    "- calculate `ApprovalRatio` as `DisbursedAmount / ApprovedAmount`.  \n",
    "- It indicates how much of the approved loan was actually disbursed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55c2be55-9ea9-4acb-9a45-698a64429e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ApprovedAmount  DisbursedAmount  ApprovalRatio\n",
      "0     24500000.00      24500000.00           1.00\n",
      "1     50000000.00      50000000.00           1.00\n",
      "2    136250000.00     136250000.00           1.00\n",
      "3      2700000.00       2700000.00           1.00\n",
      "4       233307.90        233307.90           1.00\n"
     ]
    }
   ],
   "source": [
    "if 'DisbursedAmount' in df.columns and 'ApprovedAmount' in df.columns:\n",
    "    df['ApprovalRatio'] = df['DisbursedAmount'] / df['ApprovedAmount']\n",
    "\n",
    "print(df[['ApprovedAmount', 'DisbursedAmount', 'ApprovalRatio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bd629-7f52-4d8c-b94b-33fb95e4b370",
   "metadata": {},
   "source": [
    "**2.6.4 Interest Category**\n",
    "\n",
    "- Classify loans into `InterestCategory` based on `InterestRate`.  \n",
    "- Categories: Low (0–5%), Moderate (5–10%), High (10–20%), Very High (>20%).\n",
    "- It Helps in risk profiling and comparative analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b835bf05-f0a8-491f-9de6-1bfeb9fb23ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   InterestRate InterestCategory\n",
      "0          3.13              Low\n",
      "1          3.13              Low\n",
      "2          3.13              Low\n",
      "3          3.13              Low\n",
      "4          3.13              Low\n"
     ]
    }
   ],
   "source": [
    "if 'InterestRate' in df.columns:\n",
    "    df['InterestCategory'] = pd.cut(\n",
    "        df['InterestRate'],\n",
    "        bins=[0, 5, 10, 20, 100],\n",
    "        labels=['Low', 'Moderate', 'High', 'Very High']\n",
    "    )\n",
    "\n",
    "print(df[['InterestRate', 'InterestCategory']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e7ad5-035b-4843-8efc-fe6f84c9774b",
   "metadata": {},
   "source": [
    "**2.7 Filtering or aggregating data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90794b84-4d89-48ae-adde-7ca3df020307",
   "metadata": {},
   "source": [
    "**2.7.1 Filtering Rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350c40c-75f4-457c-a968-1c095f5c6020",
   "metadata": {},
   "source": [
    "***Example 1: Filter loans approved in 2024***\n",
    "\n",
    "- Filtering loans where `FiscalYear = 2024`.  \n",
    "- It is useful for analyzing approvals specific to a given year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb79f4c4-24d4-40ce-a37e-12746232f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       FiscalYear  ApprovedAmount        Country\n",
      "49280        2024    156562500.00        Ukraine\n",
      "49281        2024     22709850.00  United States\n",
      "49282        2024     51803720.00  United States\n",
      "49283        2024     19062863.00          Japan\n",
      "49284        2024     98000000.00        Romania\n"
     ]
    }
   ],
   "source": [
    "loans_2024 = df[df['FiscalYear'] == 2024]\n",
    "print(loans_2024[['FiscalYear', 'ApprovedAmount', 'Country']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9654c-fb74-4688-8fab-899f51227fbd",
   "metadata": {},
   "source": [
    "***Example 2: Filter loans with InterestRate > 10%***\n",
    "\n",
    "- Selected loans with `InterestRate > 10%`.  \n",
    "- Helps identify higher‑risk or costlier loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84d44f78-36b6-49fc-89d6-ff1efde178ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [InterestRate, Country, ProgramType]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "high_interest_loans = df[df['InterestRate'] > 10]\n",
    "print(high_interest_loans[['InterestRate', 'Country', 'ProgramType']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2716b21-476e-40ef-9b84-b86f47640133",
   "metadata": {},
   "source": [
    "**2.7.2 Aggregating Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e734c9-d48d-4c1a-b301-a7ca7dfb1e61",
   "metadata": {},
   "source": [
    "***Example 1: Total ApprovedAmount by FiscalYear***\n",
    "\n",
    "- Grouping loans by `FiscalYear`.  \n",
    "- Calculate total `ApprovedAmount` for each year using `.sum()`.  \n",
    "- It is useful for year-wise trend analysis and budget planning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40701ba6-4fbb-4711-9486-6aabea98eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiscalYear\n",
      "2006    1141971723.67\n",
      "2007   12828061681.33\n",
      "2008   15521602468.39\n",
      "2009   28069811228.51\n",
      "2010   21795700310.39\n",
      "2011   29664372264.79\n",
      "2012   41722269785.00\n",
      "2013   21996519923.90\n",
      "2014   19451546609.31\n",
      "2015   11042188599.44\n",
      "2016    3932488951.43\n",
      "2017    3416110928.69\n",
      "2018    3142771239.61\n",
      "2019    8044012433.86\n",
      "2020    6768182834.10\n",
      "2021    5272077898.61\n",
      "2022    6004055654.53\n",
      "2023    8372962082.45\n",
      "2024    9043649031.64\n",
      "2025    2388929183.51\n",
      "Name: ApprovedAmount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by FiscalYear and sum ApprovedAmount\n",
    "approved_by_year = df.groupby('FiscalYear')['ApprovedAmount'].sum()\n",
    "print(approved_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3029c8-2a2a-469d-8b28-2cc9c763615b",
   "metadata": {},
   "source": [
    "***Example 2: Average InterestRate by Country***\n",
    "\n",
    "- Grouping loans by `Country`.  \n",
    "- Calculate average `InterestRate` using `.mean()`.  \n",
    "- It Helps to compare loan costs across regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa2f6eb8-32f2-4f3e-acf7-34ca62724cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Algeria                    3.13\n",
      "Angola                     4.08\n",
      "Argentina                  3.12\n",
      "Aruba                      3.13\n",
      "Australia                  3.08\n",
      "                           ... \n",
      "Uruguay                    3.13\n",
      "Uzbekistan                 3.13\n",
      "Vietnam                    3.13\n",
      "Virgin Islands (British)   3.13\n",
      "Zambia                     3.13\n",
      "Name: InterestRate, Length: 152, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_interest_by_country = df.groupby('Country')['InterestRate'].mean()\n",
    "print(avg_interest_by_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aeec71-7126-46af-99be-6fdc5bff9e58",
   "metadata": {},
   "source": [
    "***Example 3: Count of Loans by ProgramType***\n",
    "\n",
    "- Grouping loans by `ProgramType`.  \n",
    "- Counting number of entries using `.size()` for total rows or `.count()` for non-null `DealNumber`.  \n",
    "- This reveals program popularity and supports categorical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4370283-ed51-4cdd-9aa5-c9bcdf25dd10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProgramType\n",
      "Guarantee           2822\n",
      "Insurance          42348\n",
      "Loan                 367\n",
      "Working Capital     6155\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loan_count_by_program = df.groupby('ProgramType').size()\n",
    "print(loan_count_by_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebfd11-f4be-4135-bb90-5875f9116ca8",
   "metadata": {},
   "source": [
    "**2.8 Final Data Quality Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a86ee41-bcdf-423d-be3e-e66737091414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATA QUALITY CHECK\n",
      "\n",
      "1. Dataset Dimensions:\n",
      "  Rows: 51,692\n",
      "  Columns: 27\n",
      "\n",
      "2. Missing Values:\n",
      "  Total missing values: 823\n",
      "\n",
      "3. Data Types Summary:\n",
      "  Numeric columns: 10\n",
      "  Categorical columns: 12\n",
      "\n",
      "4. Column Data Types:\n",
      "  FiscalYear               : int32     \n",
      "  DecisionStatus           : object    \n",
      "  DecisionDate             : datetime64[ns]\n",
      "  EffectiveDate            : datetime64[ns]\n",
      "  ExpirationDate           : datetime64[ns]\n",
      "  Brokered                 : object    \n",
      "  DealCancelled            : object    \n",
      "  Country                  : object    \n",
      "  ProgramType              : object    \n",
      "  PolicyType               : object    \n",
      "  DecisionAuthority        : object    \n",
      "  ProductDescription       : object    \n",
      "  Term                     : object    \n",
      "  Exporter                 : object    \n",
      "  ExporterState            : object    \n",
      "  PSOR                     : object    \n",
      "  ApprovedAmount           : float64   \n",
      "  DisbursedAmount          : float64   \n",
      "  UndisbursedExposure      : float64   \n",
      "  OutstandingExposure      : float64   \n",
      "  SmallBusinessAmount      : float64   \n",
      "  WomenOwnedAmount         : float64   \n",
      "  MinorityOwnedAmount      : float64   \n",
      "  InterestRate             : float64   \n",
      "  LoanDuration             : int64     \n",
      "  ApprovalRatio            : float64   \n",
      "  InterestCategory         : category  \n",
      "\n",
      " Data Preprocessing Complete\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL DATA QUALITY CHECK\")\n",
    "\n",
    "# 1. Dataset dimensions\n",
    "print(\"\\n1. Dataset Dimensions:\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "\n",
    "# 2. Missing values check\n",
    "print(\"\\n2. Missing Values:\")\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"  Total missing values: {total_missing}\")\n",
    "\n",
    "# 3. Data types summary\n",
    "print(\"\\n3. Data Types Summary:\")\n",
    "print(f\"  Numeric columns: {df.select_dtypes(include=['float64','int64']).shape[1]}\")\n",
    "print(f\"  Categorical columns: {df.select_dtypes(include=['object']).shape[1]}\")\n",
    "\n",
    "# 4. Column Data Types\n",
    "print(\"\\n4. Column Data Types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  {col:25s}: {str(df[col].dtype):10s}\")\n",
    "\n",
    "print(\"\\n Data Preprocessing Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d914711-8e1f-4620-a818-c23573cd54a3",
   "metadata": {},
   "source": [
    "We verify dataset dimensions, missing values, and column data types.  \n",
    "\n",
    "The dataset is now clean, consistent, and ready for exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfbf5b-1e1a-4c0a-a82e-6510786c6d1c",
   "metadata": {},
   "source": [
    "**2.9 Exporting Cleaned Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebe922c4-da4d-4499-9700-02aff0e17764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset exported successfully!\n",
      " Location: ../data/FY25_Q3_Cleaned.csv\n",
      " Rows: 51692\n",
      " Columns: 27\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define export path\n",
    "export_path = \"../data/FY25_Q3_Cleaned.csv\"\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "os.makedirs(os.path.dirname(export_path), exist_ok=True)\n",
    "\n",
    "# Export cleaned dataset\n",
    "df.to_csv(export_path, index=False)\n",
    "\n",
    "print(\"✓ Dataset exported successfully!\")\n",
    "print(f\" Location: {export_path}\")\n",
    "print(f\" Rows: {len(df)}\")\n",
    "print(f\" Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e96928-c5b1-4bdc-b64a-865d9952dac6",
   "metadata": {},
   "source": [
    "We save the cleaned dataset as a CSV file for use in the next step (Exploratory Data Analysis).\n",
    "\n",
    "This will ensure the reproducibility and separates raw data from processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049b2db-3a06-4ae0-b587-f1401ee5ef04",
   "metadata": {},
   "source": [
    "***Reviewing the Steps Completed Above***\n",
    "\n",
    "In the first stage, the dataset was imported using pd.read_csv() and examined with .head(), .info(), and .describe() to understand its structure, column types, missing values, and basic statistics. This provided clarity on key fields such as dates, amounts, and categories, and confirmed the dataset’s shape for planning further steps. In the second stage, Data Pre-processing, the data was cleaned and standardized by renaming columns, dropping irrelevant fields, handling missing values, and removing duplicates. Data types were corrected by converting dates to datetime, numeric fields to float, and categorical fields to strings. Derived columns such as FiscalYear, LoanDurationDays, ApprovalRatio, and InterestCategory were created to enrich analysis. Finally, filtering and aggregation were applied to extract insights, including year-wise totals, average interest rates by country, and loan counts by program type. Together, these stages ensured the dataset was reliable, structured, and ready for visualization and deeper business insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
